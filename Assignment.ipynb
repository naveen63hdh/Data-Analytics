{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveen63hdh/Data-Analytics/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHa8Sd55Owo0"
      },
      "source": [
        "# 1.Creating Dataframe in Python\n",
        "\n",
        "\n",
        "> In python there are more than ways to create a dataframe using pandas. We can create dataframe from lists, tuple, dictionary, numpy array, csv file and etc. We can also create an empty dataframe and add records to it.\n",
        "\n",
        "> To create a dataframe we are loading pandas library in the alias pd, and we are also loading numpy in alias np to create dataframe from numpy array.\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj_eCvrvOwpL"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb4wbPxsOwpQ"
      },
      "source": [
        "## 1.1 Creating empty dataframe and adding records\n",
        "\n",
        "\n",
        "> DataFrame constructor is used to create a empty dataframe. The columns attribute is a list of strings which become columns of the dataframe. DataFrame rows are reference loc method with index value.                   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_3nsu7OwpT"
      },
      "source": [
        "df = pd.DataFrame(columns = [\"Emp No\",\"Emp Name\",\"Salary\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrV2mFxdOwpW"
      },
      "source": [
        "df.loc[0] = [101,\"Jai\",14000]\n",
        "df.loc[1] = [102,\"Kannan\",10000]\n",
        "df.loc[2] = [103,\"Raman\",7000]\n",
        "df.loc[3] = [104,\"Suresh\",9000]\n",
        "df.loc[4] = [105,\"Sam\",11000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lGqRs0WOwpY"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6u0LhtPOwpe"
      },
      "source": [
        "## 1.2 Creating dataframe using numpy array\n",
        "\n",
        "> In DataFrame constructor we can pass numpy array. Each row in  numpy array is the corresponding row required in the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf6xWtIkOwpg"
      },
      "source": [
        "data = np.array([[101,\"Jai\",14000],\n",
        "                 [102,\"Kannan\",10000],\n",
        "                 [103,\"Raman\",7000],\n",
        "                 [104,\"Suresh\",9000],\n",
        "                 [105,\"Sam\",11000]\n",
        "                ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYKKsyA-Owpj"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr63IDGBOwpm"
      },
      "source": [
        "df = pd.DataFrame(data,columns = [\"Emp No\",\"Emp Name\",\"Salary\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4PLAuEqOwpo"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgqY-98aOwpr"
      },
      "source": [
        "## 1.3 Creating dataframe using List\n",
        "\n",
        ">  To Create a dataframe using list we have to pass the list in DataFrame constructor and we can give column names in colum attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9X4kB8OOwpu"
      },
      "source": [
        "data = [[101,\"Jai\",14000],\n",
        "        [102,\"Kannan\",10000],\n",
        "        [103,\"Raman\",7000],\n",
        "        [104,\"Suresh\",9000],\n",
        "        [105,\"Sam\",11000]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keHrtJ60Owpw"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOYeuT4MOwpy"
      },
      "source": [
        "df = pd.DataFrame(data,columns = [\"Emp No\",\"Emp Name\",\"Salary\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEB-neGOwpz"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L6MDM4LOwp1"
      },
      "source": [
        "## 1.4 Creating dataframe using Dictionary \n",
        "\n",
        "> There are 3 ways to create a dataframe using dictonary \n",
        "\n",
        "* [Using Dictionary in DataFrame Constructor](https://colab.research.google.com/drive/1XbRrMi3RkTKGM0l4m1qsXH5LRggqSzrj#scrollTo=BlQdFRMOOwp3)\n",
        "* [Using List of Dictionary](https://colab.research.google.com/drive/1XbRrMi3RkTKGM0l4m1qsXH5LRggqSzrj#scrollTo=_L6MDM4LOwp1&line=7&uniqifier=1)\n",
        "* [Using from_dict method](https://colab.research.google.com/drive/1XbRrMi3RkTKGM0l4m1qsXH5LRggqSzrj#scrollTo=_L6MDM4LOwp1&line=7&uniqifier=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlQdFRMOOwp3"
      },
      "source": [
        "### 1.4.1 Using Dictionary in DataFrame Constructor\n",
        "\n",
        "\n",
        "> If we pass dictionary in dataframe then dictionary keys become column names of dataframe and dictionary value becomes dataframe row values. Dictionary column are combined into single row according to the order of dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjr1wrgOwp3"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKlsRdptOwp4"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmNqLMTvOwp5"
      },
      "source": [
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQOyeNQPOwp7"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDMxvMsOwp9"
      },
      "source": [
        "### 1.4.2 Using List of Dictionary\n",
        "\n",
        "> We can pass a list of dictionaries in DataFrame constructor. Each dictionary is considered as a record. Dictionary Keys become Column names in the dataframe. Dictionary values become the row values.\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxSMztWOwp-"
      },
      "source": [
        "data = [{\"Emp No\":101,\"Emp Name\":\"Jai\",\"Salary\":14000},\n",
        "        {\"Emp No\":102,\"Emp Name\":\"Kannan\",\"Salary\":10000},\n",
        "        {\"Emp No\":103,\"Emp Name\":\"Raman\",\"Salary\":7000},\n",
        "        {\"Emp No\":104,\"Emp Name\":\"Suresh\",\"Salary\":9000},\n",
        "        {\"Emp No\":105,\"Emp Name\":\"Sam\",\"Salary\":11000}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYot95RlOwqA"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHH5saMrOwqC"
      },
      "source": [
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n0CdprlOwqD"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORedkmUcOwqE"
      },
      "source": [
        "###  1.4.3 Using from_dict method\n",
        "\n",
        "> Using **from_dict** is similar to first method except here we can specify whether the keys value should be a column  name or row index. \n",
        "\n",
        "> By default keys are identified as column names but we can change it by using **orient** attribute if  we give **index** to orient attribute it will change orientation of dataframe and passes the keys as row index. \n",
        "\n",
        "> If we  give orient as index then we can specify column name using columns attribute where we pass column name as list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY_SC1IZOwqF"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN9cqEczOwqG"
      },
      "source": [
        "type(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__5_xd8XOwqH"
      },
      "source": [
        "df = pd.DataFrame().from_dict(data,orient=\"index\",columns=['Emp1','Emp2','Emp3','Emp4','Emp5'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsE8m3dOOwqI"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O67sIexOwqK"
      },
      "source": [
        "## 1.5 Creating copy of dataframe\n",
        "\n",
        "> In some scenarios me might need to do operations in dataframe without affecting the actual dataframe. In those situations we can use copy method and create a clone of the dataframe and work on it.      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrLD4EIXOwqL"
      },
      "source": [
        "df1 = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiTgZzJ1OwqN"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csN0509b3J-9"
      },
      "source": [
        "---\n",
        "# 2. Creating DataFrame from CSV and Saving it to CSV\n",
        "\n",
        "> CSV(Comma Seperated Values) is the most commonly used format used for storing tabular data like spreadsheets and database. As name suggests in csv values are seperated or delimited by comma ( , )\n",
        "\n",
        "> Pandas Provide methods for creating dataframe from a csv file and to export/save a dataframe into a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDPb0lj5paS8"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTshUtpypZfu"
      },
      "source": [
        "## 2.1 Creating DataFrame from CSV\n",
        "\n",
        "> To create dataframe from csv pandas library provides a method called read_csv. read_csv method contains many attributes some of the most commonly used attributes are.\n",
        "\n",
        "\n",
        "1.   **filepath_or_buffer** - URL/Dir location of the csv file goes here\n",
        "2.   **sep** - Delimeter of csv file. Default value is ','\n",
        "3.   **header** - Makes the passed row or rowas as column header\n",
        "4.   **index_col** - Makes passed column as index\n",
        "5.   **use_cols** - Used to retrive only specific columns\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsHxNccB-oDl"
      },
      "source": [
        "df_path = 'https://raw.githubusercontent.com/naveen63hdh/Data-Analytics/main/dataset.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3FgAs55IZpW"
      },
      "source": [
        "one_piece_df = pd.read_csv(df_path,sep = ',', header = 'infer', index_col = 'Character', usecols = ['Character','Devil Fruit','Class','Status'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFSC81t4Icek"
      },
      "source": [
        "one_piece_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opjy246sNvjX"
      },
      "source": [
        "## 2.2 Saving DataFrame as CSV\n",
        "> To save a dataframe as a csv file pandas provide a method called to_csv()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPcZLLNHQVsW"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOokWX2lQnYD"
      },
      "source": [
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S58PmvSXIdW2"
      },
      "source": [
        "df.to_csv('my_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1g9zRxwRGt9"
      },
      "source": [
        "---\n",
        "# 3. Group by operations in DataFrame\n",
        "    \n",
        "> Pandas groupby() allows us to split our data into separate groups to perform computations for better analysis. groupby() returns the **DataFrameGroupBy** object.\n",
        "\n",
        "> Using DataFrameGroupBy object we can do some analysis like getting speicfic group's values, number of groups, size of each group and etc.\n",
        "\n",
        "> Some of the attributes and methods used to access DataFrameGroupBy are:\n",
        "\n",
        "*   **ngroups** - Attribute to get number of groups\n",
        "*   **groups** - Attribute that returns groupwise row number                \n",
        "*   **size()** - Method to display group sizes\n",
        "*   **first() and last()** - Methods to preview first and last entry of each group\n",
        "*   **get_group()** - Method to retrive a dataframe for specific group\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjN5tCEHq-_3"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2k3Hbv8r3ej"
      },
      "source": [
        "df_path = 'https://raw.githubusercontent.com/naveen63hdh/Data-Analytics/main/dataset.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ENiHcIr2f4"
      },
      "source": [
        "op_df = pd.read_csv(df_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luzkfJjJr11-"
      },
      "source": [
        "devil_fruits = op_df.groupby('Class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfb67k5sxhGg"
      },
      "source": [
        "### 3.1 ngroups - Attribute to get number of **groups**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs4kA34ox4JI"
      },
      "source": [
        "devil_fruits.ngroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVoHifAMyG7X"
      },
      "source": [
        "### 3.2 groups - Attribute that returns groupwise row number                "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCaSvYM2sW1Y"
      },
      "source": [
        "devil_fruits.groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLXs_2B-ym3x"
      },
      "source": [
        "### 3.3 size() - Method to display group sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZy3cUFhyuAP"
      },
      "source": [
        "devil_fruits.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkpuA0mNy9HV"
      },
      "source": [
        "### 3.4 first() and last() - Methods to preview first and last entry of each group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfku0MnWzRuI"
      },
      "source": [
        "devil_fruits.first()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqMFRJX_zYPI"
      },
      "source": [
        "devil_fruits.last()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUeX2ABVzcKW"
      },
      "source": [
        "### 3.5 get_group() - Method to retrive a dataframe for specific group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLYhI_b7zlvR"
      },
      "source": [
        "devil_fruits.get_group('Logia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD0o7epi6Vob"
      },
      "source": [
        "---\n",
        "# 4. Combining and Merging in DataFrame\n",
        "\n",
        "> Pandas Support both Horizontal and vertical combination of dataframes. **Horizontal combination** means combining dataframes in column level **merge()** and **join()** are the methods provided by pandas for horizontal combination.And **Vertical combination** means combining dataframes in row leve **concat()** and **append()** are the methods used for vertical combination.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg71Y9HX_-kb"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJW0zZ5lADzK"
      },
      "source": [
        "## 4.1 merge() - Combining data on common columns or indices.\n",
        "\n",
        "\n",
        "> Merging two dataset can be done in two ways\n",
        "\n",
        "*   Merging dataframe with common column name\n",
        "*   Merging dataframe with different column name\n",
        "\n",
        "> Using how attribute in merge() each type can do 4 merge different operations \n",
        "\n",
        "*   Inner/Equi Join\n",
        "*   Left Join\n",
        "*   Right Join\n",
        "*   Outer Join\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCHwxSDADoZi"
      },
      "source": [
        "### 4.1.1Merging dataframe with common column name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RUNR_CwACu5"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "data2 = {'Emp No':[101,102,104,105,106,107],\n",
        "        'Team id':[201,203,201,202,202,204],\n",
        "        'Team Leader':['Vivek','Gaurav','Vivek','Vishwa','Vishwa','Guru']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJWmcr76Dqo_"
      },
      "source": [
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC-pGK8jD7Tz"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDoyOhLLD-wO"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGOp76anEkC_"
      },
      "source": [
        "### Inner/Equi Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkmTva2DEUj7"
      },
      "source": [
        "pd.merge(df1,df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERfzcA1xEzDX"
      },
      "source": [
        "pd.merge(df1,df2,how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AQFTk6jFaZ2"
      },
      "source": [
        "### Left Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SUUyrbiFesw"
      },
      "source": [
        "pd.merge(df1,df2,how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZDXrCMqFqMJ"
      },
      "source": [
        "### Right Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtIXCzSFww4"
      },
      "source": [
        "pd.merge(df1,df2,how='right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVgIIL2zF1uR"
      },
      "source": [
        "### Outer Join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL7pKawiF6db"
      },
      "source": [
        "pd.merge(df1,df2,how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBhu3lgRGIpf"
      },
      "source": [
        "### 4.1.2 Merging dataframe with different column name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIXf6FduGTUJ"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]\n",
        "        }                \n",
        "\n",
        "data2 = {'Emp Id':[101,102,104,105,106,107],\n",
        "        'Team id':[201,203,201,202,202,204],\n",
        "        'Team Leader':['Vivek','Gaurav','Vivek','Vishwa','Vishwa','Guru']\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-foza4PGZJE"
      },
      "source": [
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76NObXKQGiRw"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32hw9vwGjMp"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlZMEjjiGrn6"
      },
      "source": [
        "pd.merge(df1,df2,left_on = 'Emp No',right_on = 'Emp Id',how = 'inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSOrXyf0Ho1s"
      },
      "source": [
        "## 4.2 join() - combines data on a key column or an index.\n",
        "\n",
        ">   join() is similar to merge() both are used to combine dataframe. In join() dataframes can be combined using index but whereas in merge we can combine using both index and columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6TWB_gIH4DY"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "data2 = {'Emp No':[101,102,104,105,106,107],\n",
        "        'Team id':[201,203,201,202,202,204],\n",
        "        'Team Leader':['Vivek','Gaurav','Vivek','Vishwa','Vishwa','Guru']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URyNahOlNofF"
      },
      "source": [
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0eVmAP2OEcP"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZkwsz1WOHs3"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxS0pZ6-OIYY"
      },
      "source": [
        "df1.join(df2,lsuffix = '_l',rsuffix = '_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ksl-ktKT2-f"
      },
      "source": [
        "## 4.3 concat() - combines Data Frames across rows or columns.\n",
        "\n",
        "\n",
        "> In concat we pass the list of dataframes that need to be concatinated. Concat operation can be done in two ways\n",
        "\n",
        "\n",
        "*   Concat dataframe on axis 0 (Default Operation)\n",
        "*   Concat dataframe on axis 1 (Horizontal Operation) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuQ9S2x7GbS2"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "data2 = {'Emp No':[101,102,104,105,106,107],\n",
        "        'Team id':[201,203,201,202,202,204],\n",
        "        'Team Leader':['Vivek','Gaurav','Vivek','Vishwa','Vishwa','Guru']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xe-EIvGGyk3"
      },
      "source": [
        "df1 = pd.DataFrame(data1)\n",
        "df2 = pd.DataFrame(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSPGmEufG2HF"
      },
      "source": [
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYzxjCvWG3TU"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dekrbMeEG6ao"
      },
      "source": [
        "### 4.3.1 Concat dataframe on axis 0\n",
        "\n",
        "\n",
        "> This is the default concat operation with concats list of dataframe into single dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-hAdu7XHLo0"
      },
      "source": [
        "pd.concat([df1,df2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zoeMzf1Hz54"
      },
      "source": [
        "### 4.3.2 Concat dataframe on axis 1\n",
        "\n",
        "\n",
        "> Concating dataframe with axis 1 is similar to joins \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLEIYz-wUaY7"
      },
      "source": [
        "pd.concat([df1,df2],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPmffYe1VErd"
      },
      "source": [
        "---\n",
        "# 5.Types of Indexing in DataFrame\n",
        "\n",
        "\n",
        "> Selecting values from particular rows and columns in a dataframe is known as Indexing. By using Indexing, we can select all rows and some columns or some rows and all columns. \n",
        "\n",
        "> Indexing in DataFrame can be done in 3 ways:\n",
        "\n",
        "*   Column Name\n",
        "*   loc()\n",
        "*   iloc()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68VYowlbUhrA"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iiQkrvvXBFY"
      },
      "source": [
        "## 5.1 Indexing using column name\n",
        "\n",
        "\n",
        "> Giving column name in the index part will return only datas from given column.For indexing more than one column, column name can be passed as list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVg8xGmbXAZ_"
      },
      "source": [
        "df['Emp No']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMEZUhkvXJLu"
      },
      "source": [
        "df[['Emp No','Salary']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8BVX7HXxq0"
      },
      "source": [
        "## 5.2 loc method\n",
        "\n",
        "> Using loc() we can index row, column or both with the Label (column/row name)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCLtTKo3ZNGj"
      },
      "source": [
        "df.loc[[0,1,2],['Emp No','Salary']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8cgyoUSZ_fj"
      },
      "source": [
        "## 5.3 iloc method\n",
        "\n",
        "> iloc is similar to loc method but in iloc we use integers to index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp3W-Em5aUTo"
      },
      "source": [
        "df.iloc[:3,1:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIaaTconatbo"
      },
      "source": [
        "---\n",
        "# 6. Aggregation functions in dataframe\n",
        "\n",
        "> Pandas provides some aggregate functions to do some operations on grouped dataframe.\n",
        "\n",
        "> Some commonly used aggregation functions are\n",
        "\n",
        "*   **count()** - returns total number of items in dataframe\n",
        "*   **sum()** - returns sum of all items\n",
        "*   **mean()** - returns mean of all items\n",
        "*   **min()** - returns minimum\n",
        "*   **max()** - returns maximum\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iNECH0hnbIl"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df_path = 'https://raw.githubusercontent.com/naveen63hdh/Data-Analytics/main/bounty.csv'\n",
        "\n",
        "df = pd.read_csv(df_path)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3oukmmnngYX"
      },
      "source": [
        "## 6.1 count() - returns total number of items in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjvpRBeSoqz6"
      },
      "source": [
        "df.groupby('Status').count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OGdowpGnyZ4"
      },
      "source": [
        "## 6.2 sum() - returns sum of all items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gakOxBPwiB3"
      },
      "source": [
        "df.groupby('Status').sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8yokhG6n3PK"
      },
      "source": [
        "## 6.3 mean() - returns mean of all items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sqqdr_vwlik"
      },
      "source": [
        "df.groupby('Status').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLSK0Fwyn5yS"
      },
      "source": [
        "## 6.4 min() - returns minimum\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YmuitgDwqzX"
      },
      "source": [
        "df.groupby('Status').min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkGzvG41n7zY"
      },
      "source": [
        "## 6.5 max() - returns maximum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YFh0AonwurL"
      },
      "source": [
        "df.groupby('Status').max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fybe7x2uxR8y"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 7 Appending rows and columns to dataframe\n",
        "\n",
        "\n",
        "> In Pandas appending rows and columns to a dataframe can be done in many number of ways some of them are:\n",
        "\n",
        "*   By using append()\n",
        "*   By appending rows using loc[] method.\n",
        "*   By appending colums using lists.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdd8uqLGMS10"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2eKbHcwMXr9"
      },
      "source": [
        "## 7.1 By using append()\n",
        "\n",
        "> By using append() we can append both rows and columns from one dataframe to another. The 3 types of appending using append() are:\n",
        "\n",
        "\n",
        "*   With same index as dataframes\n",
        "*   By ignoring index\n",
        "*   With Different Shapes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d7qX3LkSAu-"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVdAN03KSH43"
      },
      "source": [
        "### 7.1.1 With same index as dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6fACOFKTC_1"
      },
      "source": [
        "data2 = {\n",
        "        'Emp No':[201,202,203,204],\n",
        "        'Emp Name':['Vivek','Gaurav','Vishwa','Guru'],\n",
        "        'Salary':[10000,13000,15000,12000]\n",
        "         }\n",
        "\n",
        "df2 = pd.DataFrame(data2)\n",
        "df1.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LWY42gRZO3E"
      },
      "source": [
        "### 7.1.2 By ignoring index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmfpnz9aZeyY"
      },
      "source": [
        "data2 = {\n",
        "        'Emp No':[201,202,203,204],\n",
        "        'Emp Name':['Vivek','Gaurav','Vishwa','Guru'],\n",
        "        'Salary':[10000,13000,15000,12000]\n",
        "         }\n",
        "\n",
        "df2 = pd.DataFrame(data2)\n",
        "df1.append(df2,ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tPec6lZaj4A"
      },
      "source": [
        "### 7.1.3 With Different Shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4DwoBAXZwir"
      },
      "source": [
        "data2 = {'Emp No':[101,102,104,105,106,107],        \n",
        "        'Team Leader':['Vivek','Gaurav','Vivek','Vishwa','Vishwa','Guru']}\n",
        "df2 = pd.DataFrame(data2)\n",
        "df1.append(df2,ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK1YIN8ubA4c"
      },
      "source": [
        "## 7.2 By appending rows using loc[] method\n",
        "\n",
        "> Create an empty DataFrame with a column name and indices and then appending rows one by one to it using loc[] method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz1BHLWKfaGX"
      },
      "source": [
        "df1 = pd.DataFrame(columns=[\"Emp Name\",\"Salary\"],index=[101,102,103,104,105])\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXcnkeqzfkKv"
      },
      "source": [
        "df1.loc[101] = ['Jai',14000]\n",
        "df1.loc[102] = ['Kannan',10000]\n",
        "df1.loc[103] = ['Raman',7000]\n",
        "df1.loc[104] = ['Suresh',9000]\n",
        "df1.loc[105] = ['Sam',11000]\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QQsFiuGgmkh"
      },
      "source": [
        "## 7.3 By appending colums using lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BleQ2eCOgqSB"
      },
      "source": [
        "data1 = {'Emp No':[101,102,103,104,105],        \n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "df1 = pd.DataFrame(data1)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zMuzKPxgxpq"
      },
      "source": [
        "empname = ['Jai','Kannan','Raman','Suresh','Sam']\n",
        "df1['Emp Name'] = empname\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibr-Sjp1hAPF"
      },
      "source": [
        "---\n",
        "# 8 Pivoting operations in dataframe\n",
        "\n",
        "\n",
        "> Pivoting dataframes reshaping datframes. In some scenario we might need to have column values as column name or index in those scenarios pivotting comes into the picture. Panda provides two methods for pivotting\n",
        "\n",
        "*   pivot() - Returns ReshapedDataFrame\n",
        "*   pivot_table() - Returns DataFrame\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meZkVuLlChXm"
      },
      "source": [
        "import pandas as pd\n",
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjdCgSD0CmFi"
      },
      "source": [
        "## 8.1 pivot()\n",
        "\n",
        "> pivot() is an extremely powerfull function that can be used to reshape dataframe based on colums values. pivot() is called using DataFrame object and it returns ReshapedDataFrame object. pivot() contains three parameters they are:\n",
        "\n",
        "*   **index** - Single/List of columns to make new frame's index\n",
        "*   **columns** - Single/List of columns to make new frame's column\n",
        "*   **values** - Sinlge/List of columns to populate new frame\n",
        "\n",
        "**Syntax :**\n",
        "```\n",
        "pivot(index,columns,values)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ukyyn6oCqfr"
      },
      "source": [
        "df.pivot(index ='Emp No',columns = 'Emp Name',values = 'Salary' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YfKYI55Fnha"
      },
      "source": [
        "## 8.2 pivot_table()\n",
        "\n",
        "> Like pivot() pivot_table() is also used to reshape dataframe but pivot_table returns DataFrame which look like excel style pivot table. And pivot_table is called using pandas object. pivot_table provides many parameter some of the important params are:\n",
        "\n",
        "\n",
        "*   **data** - DataFrame object which holds data\n",
        "*   **index** - Single/List of columns to make new frame's index\n",
        "*   **columns** - Single/List of columns to make new frame's column\n",
        "*   **values** - Sinlge/List of columns to populate new frame\n",
        "\n",
        "**Syntax :**\n",
        "```\n",
        "pivot_table(data,index,columns,values)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qcyr4GKxIGVX"
      },
      "source": [
        "df2 = pd.pivot_table(data = df,index = 'Emp Name',columns = 'Emp No',values ='Salary')\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFtzd9UkJEqa"
      },
      "source": [
        "type(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYOXHf05MoFr"
      },
      "source": [
        "---\n",
        "# 9. Different possible operations to a DataFrame\n",
        "\n",
        "> Pandas provides rich set of methods to work with DataFrames. All the methods we discussed above is just a small part. There are more methods which are useful for dataframe operations some of them are:\n",
        "\n",
        "*   transpose()\n",
        "*   sample()\n",
        "*   replace()\n",
        "*   fillna()\n",
        "*   describe()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JJJOB0oUiB0"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8p7iSAEUkv9"
      },
      "source": [
        "## 9.1 transpose()\n",
        "\n",
        "> As name suggests transpose() is used to convert dataframe's index to column and columns to index. Using this we can get the transpose matrix of dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inqi_f5HUrX3"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,11000]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFkrf7LXUwgr"
      },
      "source": [
        "df.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBQ1Q5j5VotT"
      },
      "source": [
        "## 9.2 sample()\n",
        "\n",
        "> In some scenarios we might need some random which doesn't have any common pattern using sample() we can achieve that sample() retrives some random datas from dataframe. Using n attribute of sample() we can say how many number of random data needs to be retrived.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KadjA_tWTKh"
      },
      "source": [
        "df_path = 'https://raw.githubusercontent.com/naveen63hdh/Data-Analytics/main/dataset.csv'\n",
        "\n",
        "one_piece = pd.read_csv(df_path)\n",
        "one_piece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aprRHRdkWfyC"
      },
      "source": [
        "one_piece.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4qTYkfjW57M"
      },
      "source": [
        "## 9.3 replace()\n",
        "\n",
        "> replace() is used to replace string, dictionaries, list, series and even regex. The value(s) or the regex expression to be replaced will be given in *to_replace* attribute and the string. The new value is given in *value* attribute. If we are using regex expression then *regex* attribute should be flagged as True.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRzclYvHdHAe"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,10000,7000,9000,10000]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Ygv-kvfS_6"
      },
      "source": [
        "df.replace(10000,12000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk_nugRAeIYu"
      },
      "source": [
        "df.replace('Ka.+','Ramu',regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8JPbh9ffuRU"
      },
      "source": [
        "## 9.4 fillna()\n",
        "\n",
        "> fillna() is used to fill the null/NaN values with custom values in the dataframe. *value* attribute is used to give the custom null value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIK3ge0ugZCr"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000,None,7000,None,10000]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGNew1s8hn9e"
      },
      "source": [
        "df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vee7aTJviHzc"
      },
      "source": [
        "## 9.5 describe()\n",
        "\n",
        "> Describe method gives a brief summary of datas in dataframe. It gives values for **count, mean, std, min, max, 25%,50% and 75%**. Using include adn exclude attributes we can say the datatupes that need to be included and excluded.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaEeTG7PlzuO"
      },
      "source": [
        "data = {'Emp No':[101,102,103,104,105],\n",
        "        'Emp Name':['Jai','Kannan','Raman','Suresh','Sam'],\n",
        "        'Salary':[14000.0,10000.0,7000.0,9000.0,10000.0]}                \n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuiIvosGh71X"
      },
      "source": [
        "df.describe(include=float)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}